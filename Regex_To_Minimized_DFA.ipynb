{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaj3Kvq8fYFM"
      },
      "source": [
        "# **<font color='red'>Part 1: Error Checking</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-C2L3Wk0gQLJ"
      },
      "outputs": [],
      "source": [
        "def checkErrors(regex):\n",
        "  parCount = 0\n",
        "  sqrCount = 0\n",
        "\n",
        "  for i, char in enumerate(regex):\n",
        "    if char == '(':\n",
        "      parCount += 1\n",
        "    elif char == ')':\n",
        "      parCount -= 1\n",
        "      if parCount < 0:\n",
        "        return False\n",
        "    elif char == '[':\n",
        "      if ((i+1 == len(regex)) or (not regex[i+1].isalnum())):\n",
        "        return False\n",
        "      sqrCount += 1\n",
        "    elif char == ']':\n",
        "      sqrCount -= 1\n",
        "      if sqrCount < 0:\n",
        "        return False\n",
        "    elif char == '-':\n",
        "      if (not regex[i-1].isalnum()) or ((i+1 == len(regex)) or (not regex[i+1].isalnum())) or (ord(regex[i-1]) > ord(regex[i+1])):\n",
        "        return False\n",
        "    elif char in ['*', '?', '+']:\n",
        "      if ((i+1 != len(regex)) and (regex[i+1] in ['*', '?', '+'])):\n",
        "        return False\n",
        "\n",
        "  if (sqrCount != 0) or (parCount != 0):\n",
        "    return False\n",
        "\n",
        "  return True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3EEBODpkUJg"
      },
      "source": [
        "# **<font color='red'>Part 2: Regex To NFA</font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjbewnyXSVwb"
      },
      "source": [
        "## **1- Infix to Postfix**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAi_3PIcCxQA"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MEbva3TBJtHU"
      },
      "outputs": [],
      "source": [
        "class rng:\n",
        "\n",
        "  def __init__(self, txt):\n",
        "    self.txt = txt\n",
        "\n",
        "  def showTxt(self):\n",
        "    return self.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YKo1IE5m_74k"
      },
      "outputs": [],
      "source": [
        "def concat(infix):\n",
        "\n",
        "  new_infix = \"\"\n",
        "\n",
        "  for i in range(len(infix) - 1):\n",
        "    new_infix += infix[i]\n",
        "\n",
        "    if (infix[i] in ['*','+','?',']',')']  and infix[i+1] not in ['*','+','?',']', '|', ')']):\n",
        "      new_infix += '•'\n",
        "\n",
        "    elif ((infix[i].isalnum() or infix[i] == '.') and (infix[i+1].isalnum() or infix[i] == '.' or infix[i+1] in ['(','['])):\n",
        "       new_infix += '•'\n",
        "\n",
        "  new_infix += infix[-1]\n",
        "  return new_infix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INBzNPGWKvUT"
      },
      "outputs": [],
      "source": [
        "def tokenizeRngs(infix):\n",
        "\n",
        "  new_infix = list()\n",
        "  rngString = \"\"\n",
        "  rngFlag = False\n",
        "\n",
        "  for char in infix:\n",
        "\n",
        "    if char == '[':\n",
        "      rngFlag = True\n",
        "      continue\n",
        "\n",
        "    elif char == ']':\n",
        "      rngObj = rng(rngString)\n",
        "      new_infix.append(rngObj)\n",
        "      rngFlag = False\n",
        "      rngString = \"\"\n",
        "      continue\n",
        "\n",
        "    if rngFlag:\n",
        "      rngString += char\n",
        "\n",
        "    else:\n",
        "      new_infix.append(char)\n",
        "\n",
        "  return new_infix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEujvM3VO0yd"
      },
      "source": [
        "### Shunting Yard\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wc0ExadaO73o"
      },
      "outputs": [],
      "source": [
        "precedence = {'*': 5, '+': 4, '?': 3, '•': 2, '|': 1, '(': 0}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwwHlavWQ7fY"
      },
      "outputs": [],
      "source": [
        "def shuntingYard(infix):\n",
        "\n",
        "  #Preprocessing Steps\n",
        "  infix = concat(infix)\n",
        "  infix = tokenizeRngs(infix)\n",
        "  #Shunting Yard Algorithm\n",
        "  stack = list()\n",
        "  postfix = list()\n",
        "\n",
        "  for char in infix:\n",
        "\n",
        "    if char == '(':\n",
        "      stack.append(char)\n",
        "\n",
        "    elif char == ')':\n",
        "      while (stack[-1] != '('):\n",
        "        postfix.append(stack.pop())\n",
        "      stack.pop()\n",
        "\n",
        "    elif char in precedence.keys():\n",
        "      while (stack and (precedence[char] <= precedence[stack[-1]])):\n",
        "        postfix.append(stack.pop())\n",
        "      stack.append(char)\n",
        "\n",
        "    else:\n",
        "      postfix.append(char)\n",
        "\n",
        "  while stack:\n",
        "    postfix.append(stack.pop())\n",
        "\n",
        "  return postfix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6rKc2AmrFTA"
      },
      "source": [
        "## **2- Postfix to NFA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfQXdirjeWMl"
      },
      "source": [
        "### Graph OOP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDFj9JKfr5AD"
      },
      "outputs": [],
      "source": [
        "class edge:\n",
        "  def __init__(self, edge_to, value):\n",
        "    self.edge_to = edge_to\n",
        "    self.value = value\n",
        "\n",
        "\n",
        "class state:\n",
        "  def __init__(self, name, id):\n",
        "    self.name = name\n",
        "    self.id = id\n",
        "    self.edges = list()\n",
        "\n",
        "class nfa:\n",
        "  def __init__(self, starting, terminating):\n",
        "    self.starting = starting\n",
        "    self.terminating = terminating\n",
        "    self.states = list()\n",
        "\n",
        "class nfaOps:\n",
        "  def buildNFA(self, edgeValue, stateNum):\n",
        "\n",
        "    state1 = state('S' + str(stateNum), stateNum)\n",
        "    state2 = state('S' + str(stateNum + 1), stateNum + 1)\n",
        "    state1.edges.append(edge(state2, edgeValue))\n",
        "    newNFA = nfa(state1, state2)\n",
        "    newNFA.states.extend([state1, state2])\n",
        "    return newNFA\n",
        "\n",
        "  def concatNFAs(self, nfa1, nfa2):\n",
        "\n",
        "    nfa1.terminating.edges.append(edge(nfa2.starting, 'ε'))\n",
        "    newNFA = nfa(nfa1.starting, nfa2.terminating)\n",
        "    newNFA.states.extend(nfa1.states + nfa2.states)\n",
        "    return newNFA\n",
        "\n",
        "  def orNFAS(self, nfa1, nfa2, stateNum):\n",
        "\n",
        "    state1 = state('S' + str(stateNum), stateNum)\n",
        "    state2 = state('S' + str(stateNum + 1), stateNum + 1)\n",
        "    state1.edges.append(edge(nfa1.starting, 'ε'))\n",
        "    state1.edges.append(edge(nfa2.starting, 'ε'))\n",
        "    nfa1.terminating.edges.append(edge(state2, 'ε'))\n",
        "    nfa2.terminating.edges.append(edge(state2, 'ε'))\n",
        "    newNFA = nfa(state1, state2)\n",
        "    newNFA.states.extend([state1, state2])\n",
        "    newNFA.states.extend(nfa1.states + nfa2.states)\n",
        "    return newNFA\n",
        "\n",
        "  def zeroOrMoreNFA(self, nfa1, stateNum):\n",
        "\n",
        "    state1 = state('S' + str(stateNum), stateNum)\n",
        "    state2 = state('S' + str(stateNum + 1), stateNum + 1)\n",
        "    state1.edges.append(edge(nfa1.starting, 'ε'))\n",
        "    state1.edges.append(edge(state2, 'ε'))\n",
        "    nfa1.terminating.edges.append(edge(state2, 'ε'))\n",
        "    nfa1.terminating.edges.append(edge(nfa1.starting, 'ε'))\n",
        "    newNFA = nfa(state1, state2)\n",
        "    newNFA.states.extend([state1, state2])\n",
        "    newNFA.states.extend(nfa1.states)\n",
        "    return newNFA\n",
        "\n",
        "  def oneOrMoreNFA(self, nfa1, stateNum):\n",
        "\n",
        "    state1 = state('S' + str(stateNum), stateNum)\n",
        "    state2 = state('S' + str(stateNum + 1), stateNum + 1)\n",
        "    state1.edges.append(edge(nfa1.starting, 'ε'))\n",
        "    nfa1.terminating.edges.append(edge(state2, 'ε'))\n",
        "    nfa1.terminating.edges.append(edge(nfa1.starting, 'ε'))\n",
        "    newNFA = nfa(state1, state2)\n",
        "    newNFA.states.extend([state1, state2])\n",
        "    newNFA.states.extend(nfa1.states)\n",
        "    return newNFA\n",
        "\n",
        "  def zeroOrOneNFA(self, nfa1, stateNum):\n",
        "\n",
        "    state1 = state('S' + str(stateNum), stateNum)\n",
        "    state2 = state('S' + str(stateNum + 1), stateNum + 1)\n",
        "    state1.edges.append(edge(nfa1.starting, 'ε'))\n",
        "    state1.edges.append(edge(state2, 'ε'))\n",
        "    nfa1.terminating.edges.append(edge(state2, 'ε'))\n",
        "    newNFA = nfa(state1, state2)\n",
        "    newNFA.states.extend([state1, state2])\n",
        "    newNFA.states.extend(nfa1.states)\n",
        "    return newNFA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xA9FjT_qeeHj"
      },
      "source": [
        "### Constructing Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ox11WAMNHf-"
      },
      "outputs": [],
      "source": [
        "def postfixToNFA(postfix):\n",
        "\n",
        "    stack = list()\n",
        "    id = 0\n",
        "    ops = nfaOps()\n",
        "\n",
        "    for char in postfix:\n",
        "\n",
        "      if(char == '•'):\n",
        "        nfa1 = stack.pop()\n",
        "        nfa2 = stack.pop()\n",
        "        newNFA = ops.concatNFAs(nfa2, nfa1)\n",
        "        stack.append(newNFA)\n",
        "\n",
        "      elif(char == '|'):\n",
        "        nfa1 = stack.pop()\n",
        "        nfa2 = stack.pop()\n",
        "        newNFA = ops.orNFAS(nfa2, nfa1, id)\n",
        "        stack.append(newNFA)\n",
        "        id += 2\n",
        "\n",
        "      elif(char == '*'):\n",
        "        nfa1 = stack.pop()\n",
        "        newNFA = ops.zeroOrMoreNFA(nfa1, id)\n",
        "        stack.append(newNFA)\n",
        "        id += 2\n",
        "\n",
        "      elif(char == '+'):\n",
        "        nfa1 = stack.pop()\n",
        "        newNFA = ops.oneOrMoreNFA(nfa1, id)\n",
        "        stack.append(newNFA)\n",
        "        id += 2\n",
        "\n",
        "      elif(char == '?'):\n",
        "        nfa1 = stack.pop()\n",
        "        newNFA = ops.zeroOrOneNFA(nfa1, id)\n",
        "        stack.append(newNFA)\n",
        "        id += 2\n",
        "\n",
        "      else:\n",
        "        newNFA = ops.buildNFA(char if isinstance(char,str) else char.showTxt().replace('•', ''), id)\n",
        "        stack.append(newNFA)\n",
        "        id += 2\n",
        "\n",
        "    newNFA = stack[-1]\n",
        "    return newNFA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Sk8e5oLesS4"
      },
      "source": [
        "### Generating JSON file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBXxECfWd1xW"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def nfaJSON(NFA):\n",
        "\n",
        "  graph = dict()\n",
        "  NFA.states.sort(key=lambda x: x.id)\n",
        "  graph[\"startingState\"] = NFA.starting.name\n",
        "\n",
        "  for state in NFA.states:\n",
        "\n",
        "    graph[state.name] = {\"isTerminatingState\": True if state == NFA.terminating else False}\n",
        "\n",
        "    for edge in state.edges:\n",
        "\n",
        "      if edge.value in graph[state.name]:\n",
        "        graph[state.name][edge.value] = list() + [graph[state.name][edge.value]] + [edge.edge_to.name]\n",
        "      else:\n",
        "        graph[state.name][edge.value] = edge.edge_to.name\n",
        "\n",
        "  with open(\"NFA.json\", \"w\") as outfile:\n",
        "    json.dump(graph, outfile, indent= '\\t', ensure_ascii=False)\n",
        "\n",
        "  return graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCJO1MEK-viC"
      },
      "source": [
        "### Wrapper Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_Fk5RqJ99P2"
      },
      "outputs": [],
      "source": [
        "def regexToNFA(regex):\n",
        "  out = shuntingYard(regex)\n",
        "  NFA = postfixToNFA(out)\n",
        "  NFA = nfaJSON(NFA)\n",
        "  return NFA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUq1s2mEk7ym"
      },
      "source": [
        "# **<font color='red'>Part 2: NFA To Minimized DFA</font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UTrzDE4njV5"
      },
      "source": [
        "## **1- NFA To DFA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXwpQnhPYAe8"
      },
      "source": [
        "### Some utility functions for range handling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tFmsJKpYQdr"
      },
      "outputs": [],
      "source": [
        "def expand_alphanumeric_range(input_str):\n",
        "  expanded_str = ''\n",
        "  i = 0\n",
        "  while i < len(input_str):\n",
        "      if input_str[i] == '.':\n",
        "          expanded_str += ''.join(chr(c) for c in range(ord('0'), ord('9') + 1))\n",
        "          expanded_str += ''.join(chr(c) for c in range(ord('A'), ord('Z') + 1))\n",
        "          expanded_str += ''.join(chr(c) for c in range(ord('a'), ord('z') + 1))\n",
        "          i += 1\n",
        "      elif i + 2 < len(input_str) and input_str[i + 1] == '-':\n",
        "          start_char = input_str[i]\n",
        "          end_char = input_str[i + 2]\n",
        "          expanded_str += ''.join(chr(c) for c in range(ord(start_char), ord(end_char) + 1))\n",
        "          i += 3\n",
        "      else:\n",
        "          expanded_str += input_str[i]\n",
        "          i += 1\n",
        "  expanded_str = ''.join(sorted(expanded_str))\n",
        "  return expanded_str\n",
        "\n",
        "def str_intersections(ranges_list):\n",
        "  new_ranges = list()\n",
        "  new_possible_edges = set()\n",
        "  for i in range(0, len(ranges_list)):\n",
        "    if len(ranges_list[i]) > 1:\n",
        "      new_str = ranges_list[i]\n",
        "      lst = list()\n",
        "      for edge in new_possible_edges:\n",
        "        k = 0\n",
        "        cut_flag = False\n",
        "        cut_string = \"\"\n",
        "        for j in range(len(ranges_list[i])):\n",
        "          if ranges_list[i][j] == edge[k]:\n",
        "            cut_string += edge[k]\n",
        "            k += 1\n",
        "\n",
        "          elif (ranges_list[i][j] != edge[k]) and (len(cut_string) > 0):\n",
        "            cut_flag = True\n",
        "\n",
        "          if (cut_flag) or (((j == len(ranges_list[i]) - 1) or (k == len(edge))) and (len(cut_string) > 0)):\n",
        "            new_str = new_str.replace(cut_string, '')\n",
        "            lst.append(cut_string)\n",
        "\n",
        "            for m in range(len(new_ranges)):\n",
        "              for n in range(len(new_ranges[m])):\n",
        "                if (cut_string in new_ranges[m][n]) and (len(new_ranges[m][n]) > len(cut_string)):\n",
        "                  new_ranges[m][n] = new_ranges[m][n].replace(cut_string, '')\n",
        "                  new_ranges[m].append(cut_string)\n",
        "\n",
        "            cut_flag = False\n",
        "            cut_string = \"\"\n",
        "            if not cut_flag:\n",
        "              break\n",
        "\n",
        "      lst.append(new_str)\n",
        "      new_possible_edges.update(lst)\n",
        "      new_ranges.append(lst)\n",
        "    else:\n",
        "      new_ranges.append([ranges_list[i]])\n",
        "      new_possible_edges.add(ranges_list[i])\n",
        "\n",
        "  return new_ranges\n",
        "\n",
        "def group_consecutive_chars(input_str):\n",
        "  result = []\n",
        "  i = 0\n",
        "  while i < len(input_str):\n",
        "      start = input_str[i]\n",
        "      end = start\n",
        "      while i + 1 < len(input_str) and ord(input_str[i + 1]) == ord(input_str[i]) + 1:\n",
        "          end = input_str[i + 1]\n",
        "          i += 1\n",
        "      if start != end:\n",
        "          result.append(f\"{start}-{end}\")\n",
        "      else:\n",
        "          result.append(start)\n",
        "      i += 1\n",
        "  result_str = ''.join(result)\n",
        "  if result_str == \"a-zA-Z0-9\":\n",
        "      return \".\"\n",
        "  return result_str\n",
        "\n",
        "def handle_intersecting_ranges(ranges_list):\n",
        "  expanded_ranges = [expand_alphanumeric_range(rng) for rng in ranges_list]\n",
        "  edges_mapping = dict(zip(ranges_list, expanded_ranges))\n",
        "  edges_mapping = dict(sorted(edges_mapping.items(), key=lambda item: len(item[1])))\n",
        "  edges_expansion = str_intersections(list(edges_mapping.values()))\n",
        "  new_possible_edges = set()\n",
        "  for i in range(len(edges_expansion)):\n",
        "    for j in range(len(edges_expansion[i])):\n",
        "      if len(edges_expansion[i][j]) > 1:\n",
        "        edges_expansion[i][j] = group_consecutive_chars(edges_expansion[i][j])\n",
        "        new_possible_edges.add(edges_expansion[i][j])\n",
        "      else:\n",
        "        new_possible_edges.add(edges_expansion[i][j])\n",
        "  edges_mapping = dict(zip(edges_mapping.keys(), edges_expansion))\n",
        "\n",
        "  return edges_mapping, new_possible_edges"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xb8td23FYnmB"
      },
      "source": [
        "### Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjfPeOctlF2U"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "\n",
        "def nfaToDfa(nfaFilePath = \"NFA.json\", nfa = None):\n",
        "\n",
        "  #Load JSON file\n",
        "  if not nfa:\n",
        "    with open(nfaFilePath) as json_file:\n",
        "      NFA = json.load(json_file)\n",
        "  else:\n",
        "    NFA = nfa\n",
        "\n",
        "  #Set the starting state of DFA\n",
        "  queue = [{NFA['startingState']}]\n",
        "  termFlag = False\n",
        "  if 'ε' in NFA[NFA['startingState']].keys():\n",
        "    epsEdges = list(NFA[NFA['startingState']]['ε']) if isinstance(NFA[NFA['startingState']]['ε'], list) else [NFA[NFA['startingState']]['ε']]\n",
        "    queue[0].update(epsEdges)\n",
        "    while epsEdges:\n",
        "      nextEdge = epsEdges.pop(0)\n",
        "      if NFA[nextEdge][\"isTerminatingState\"]:\n",
        "        termFlag = True\n",
        "      if 'ε' in NFA[nextEdge].keys():\n",
        "        newLst = list(NFA[nextEdge]['ε']) if isinstance(NFA[nextEdge]['ε'], list) else [NFA[nextEdge]['ε']]\n",
        "        queue[0].update(newLst)\n",
        "        epsEdges.extend(newLst)\n",
        "\n",
        "  #Set the graph of DFA\n",
        "  DFAStates = {str(queue[0]): 'S0'}\n",
        "  id = 1\n",
        "  graph = {\"startingState\": 'S0'}\n",
        "  graph['S0'] = {\"isTerminatingState\": termFlag}\n",
        "\n",
        "  #Start of Conversion\n",
        "  while queue:\n",
        "    currentState = queue.pop(0)\n",
        "\n",
        "    #Get all possible edge transitions\n",
        "    possibleEdges = [key for state in currentState for key in list(NFA[state].keys())[1:]]\n",
        "    possibleEdges = set(possibleEdges)\n",
        "    possibleEdges.discard('ε')\n",
        "\n",
        "    #Fix edges with ranges\n",
        "    edgesMapping, possibleEdges = handle_intersecting_ranges(possibleEdges)\n",
        "\n",
        "    #Create new local NFA with new edge transitions\n",
        "    NFA_copy = copy.deepcopy(NFA)\n",
        "    for edge in edgesMapping.keys():\n",
        "      for state in currentState:\n",
        "        if edge in NFA_copy[state].keys():\n",
        "          if len(edgesMapping[edge]) > 1:\n",
        "            for newEdge in edgesMapping[edge]:\n",
        "              NFA_copy[state][newEdge] = NFA_copy[state][edge]\n",
        "          else:\n",
        "            if edgesMapping[edge][0] != edge:\n",
        "              NFA_copy[state][edgesMapping[edge][0]] = NFA_copy[state][edge]\n",
        "              del NFA_copy[state][edge]\n",
        "            break\n",
        "          del NFA_copy[state][edge]\n",
        "\n",
        "    #Iterate over new edges and new NFA\n",
        "    for edge in possibleEdges:\n",
        "      newState = set()\n",
        "      termFlag = False\n",
        "      for state in currentState:\n",
        "        if edge in NFA_copy[state].keys():\n",
        "          newState.add(NFA_copy[state][edge])\n",
        "          epsEdges = [NFA_copy[state][edge]]\n",
        "          while epsEdges:\n",
        "            nextEdge = epsEdges.pop(0)\n",
        "            if NFA_copy[nextEdge][\"isTerminatingState\"]:\n",
        "              termFlag = True\n",
        "            if 'ε' in NFA_copy[nextEdge].keys():\n",
        "              newLst = list(NFA_copy[nextEdge]['ε']) if isinstance(NFA_copy[nextEdge]['ε'], list) else [NFA_copy[nextEdge]['ε']]\n",
        "              newState.update(newLst)\n",
        "              epsEdges.extend(newLst)\n",
        "\n",
        "      if (newState and newState not in queue and str(newState) not in DFAStates.keys()):\n",
        "        queue.append(newState)\n",
        "\n",
        "      if (newState and str(newState) not in DFAStates.keys()):\n",
        "        DFAStates[str(newState)] = 'S' + str(id)\n",
        "        id += 1\n",
        "        graph[DFAStates[str(newState)]] = {\"isTerminatingState\": termFlag}\n",
        "        graph[DFAStates[str(currentState)]][edge] = DFAStates[str(newState)]\n",
        "\n",
        "      elif(newState):\n",
        "        graph[DFAStates[str(currentState)]][edge] = DFAStates[str(newState)]\n",
        "\n",
        "  with open(\"DFA.json\", \"w\") as outfile:\n",
        "    json.dump(graph, outfile, indent= '\\t')\n",
        "\n",
        "  return graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rk_Q9f55gsx1"
      },
      "source": [
        "## **2- Minimize DFA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qccXCSF8h7Ne"
      },
      "outputs": [],
      "source": [
        "def MinimizeDFA(nfaFilePath = \"NFA.json\", nfa = None, dfa = None):\n",
        "\n",
        "  #Get DFA\n",
        "  DFA = (nfaToDfa(nfaFilePath= nfaFilePath) if not nfa else nfaToDfa(nfa= nfa)) if not dfa else dfa\n",
        "\n",
        "  #Get all possible edge transitions\n",
        "  states = list(DFA.values())[1:]\n",
        "  possibleEdges = [key for edge in states for key in list(edge.keys())[1:]]\n",
        "  possibleEdges = set(possibleEdges)\n",
        "\n",
        "  #Group states into terminating and non-terminating groups\n",
        "  stateGroups = {0: [], 1: []}\n",
        "  groupMapping = dict()\n",
        "  for key,value in list(DFA.items())[1:]:\n",
        "    if not value['isTerminatingState']:\n",
        "      stateGroups[0].append(key)\n",
        "      groupMapping[key] = 0\n",
        "    else:\n",
        "      stateGroups[1].append(key)\n",
        "      groupMapping[key] = 1\n",
        "  queue = [(key, value) for key,value in stateGroups.items()]\n",
        "\n",
        "  #Process each group:\n",
        "  id = 1\n",
        "  while queue:\n",
        "    i, stateGroup = queue.pop(0)\n",
        "\n",
        "    if len(stateGroup) > 1:\n",
        "      group = [x for x in stateGroup]\n",
        "\n",
        "      for edge in possibleEdges:\n",
        "        transitionGroup = dict()\n",
        "\n",
        "        for state in group:\n",
        "          if edge in DFA[state].keys():\n",
        "            transitionGroup[state] = groupMapping[DFA[state][edge]]\n",
        "          else:\n",
        "            transitionGroup[state] = \"\"\n",
        "\n",
        "        #Compare by the transition group of the first state\n",
        "        cmpGroup = list(transitionGroup.values())[0]\n",
        "\n",
        "        for transitionI in transitionGroup.keys():\n",
        "          if (transitionGroup[transitionI] != cmpGroup) and (transitionI in group):\n",
        "            id += 1\n",
        "            groupMapping[transitionI] = id\n",
        "            newGroup = list()\n",
        "            newGroup.append(transitionI)\n",
        "            group.remove(transitionI)\n",
        "            stateGroups[i].remove(transitionI)\n",
        "            for transitionJ in group:\n",
        "              if transitionGroup[transitionJ] == transitionGroup[transitionI]:\n",
        "                groupMapping[transitionJ] = id\n",
        "                newGroup.append(transitionJ)\n",
        "                stateGroups[i].remove(transitionJ)\n",
        "\n",
        "            group = [x for x in stateGroups[i]]\n",
        "            queue.append((id, newGroup))\n",
        "            stateGroups[id] = newGroup\n",
        "\n",
        "        if stateGroups[i] != stateGroup:\n",
        "          queue.append((i, group))\n",
        "\n",
        "  #Generating graph and JSON file:\n",
        "  graph = dict()\n",
        "\n",
        "  for index, group in stateGroups.items():\n",
        "    if DFA['startingState'] in group:\n",
        "      graph['startingState'] = 'S' + str(index)\n",
        "\n",
        "  for index, group in stateGroups.items():\n",
        "    if group:\n",
        "      graph['S' + str(index)] = {'isTerminatingState': DFA[group[0]]['isTerminatingState']}\n",
        "\n",
        "      for edge in list(DFA[group[0]].keys())[1:]:\n",
        "        graph['S' + str(index)][edge] = 'S' + str(groupMapping[DFA[group[0]][edge]])\n",
        "\n",
        "  with open(\"MinimizedDFA.json\", \"w\") as outfile:\n",
        "    json.dump(graph, outfile, indent= '\\t')\n",
        "\n",
        "  return DFA, graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycBLXqxg9kZ6"
      },
      "source": [
        "# **<font color='red'>Part 3: Bringing It All Together (Regex To Minimized DFA)</font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7yi0I_VJ00w"
      },
      "source": [
        "## **Visualization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOxC80xkKMg0"
      },
      "outputs": [],
      "source": [
        "import pydot\n",
        "\n",
        "def visualGraph(graphName, pathToJSON = None, graph= None):\n",
        "\n",
        "  #Load JSON file or dictionary graph\n",
        "  if not graph:\n",
        "    with open(pathToJSON) as json_file:\n",
        "      graph = json.load(json_file)\n",
        "  else:\n",
        "    graph = graph\n",
        "\n",
        "  #Preparing visual graph\n",
        "  visual = pydot.Dot(graphName, graph_type= \"digraph\")\n",
        "\n",
        "  #Create all nodes\n",
        "  for state in graph.keys():\n",
        "    if state == 'startingState':\n",
        "      visual.add_node(pydot.Node('Starting Node', style= \"invis\"))\n",
        "      visual.add_node(pydot.Node(graph['startingState'], label= graph[state], shape= \"circle\"))\n",
        "      visual.add_edge(pydot.Edge('Starting Node', graph['startingState'], label=\"Start\", style= \"solid\", color=\"red\"))\n",
        "    elif state != graph['startingState']:\n",
        "      visual.add_node(pydot.Node(state, label= state, shape= \"doublecircle\" if graph[state]['isTerminatingState'] else \"circle\"))\n",
        "\n",
        "  #Create all edges\n",
        "  for state in list(graph.keys())[1:]:\n",
        "    for edge in list(graph[state].keys())[1:]:\n",
        "      if isinstance(graph[state][edge], str):\n",
        "        visual.add_edge(pydot.Edge(state, graph[state][edge], label= edge, style= \"solid\"))\n",
        "      else:\n",
        "        for epsEdge in graph[state][edge]:\n",
        "          visual.add_edge(pydot.Edge(state, epsEdge, label= edge, style= \"solid\"))\n",
        "\n",
        "  #Save into image\n",
        "  visual.write_png(graphName + \".png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jg7xlhoQJ90k"
      },
      "source": [
        "## **Wrapper Function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQ66NDkGzLcz"
      },
      "outputs": [],
      "source": [
        "def regextoMinimizedDFA(regex):\n",
        "  #Check for errors:\n",
        "  if not checkErrors(regex):\n",
        "    print(\"Please Check The Validity Of The Entered Regex\")\n",
        "    return False\n",
        "\n",
        "  #NFA\n",
        "  NFA = regexToNFA(regex)\n",
        "  fileNFA = visualGraph(\"NFA\", graph= NFA)\n",
        "\n",
        "  #DFA & Minimized DFA\n",
        "  DFA, minimizedDFA = MinimizeDFA(nfa= NFA)\n",
        "  fileDFA = visualGraph(\"DFA\", graph= DFA)\n",
        "  fileMinimizeNFA = visualGraph(\"MinimizedDFA\", graph= minimizedDFA)\n",
        "  return NFA, DFA, minimizedDFA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9aMR7DJdns7"
      },
      "source": [
        "## **Input from user**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBi-oE9gCcJU",
        "outputId": "82912859-1ba5-4515-98b6-ec8bb8814841"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please Enter a Regex: AB(A|B)*AB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'startingState': 'S0',\n",
              "  'S0': {'isTerminatingState': False, 'A': 'S1'},\n",
              "  'S1': {'isTerminatingState': False, 'ε': 'S2'},\n",
              "  'S2': {'isTerminatingState': False, 'B': 'S3'},\n",
              "  'S3': {'isTerminatingState': False, 'ε': 'S10'},\n",
              "  'S4': {'isTerminatingState': False, 'A': 'S5'},\n",
              "  'S5': {'isTerminatingState': False, 'ε': 'S9'},\n",
              "  'S6': {'isTerminatingState': False, 'B': 'S7'},\n",
              "  'S7': {'isTerminatingState': False, 'ε': 'S9'},\n",
              "  'S8': {'isTerminatingState': False, 'ε': ['S4', 'S6']},\n",
              "  'S9': {'isTerminatingState': False, 'ε': ['S11', 'S8']},\n",
              "  'S10': {'isTerminatingState': False, 'ε': ['S8', 'S11']},\n",
              "  'S11': {'isTerminatingState': False, 'ε': 'S12'},\n",
              "  'S12': {'isTerminatingState': False, 'A': 'S13'},\n",
              "  'S13': {'isTerminatingState': False, 'ε': 'S14'},\n",
              "  'S14': {'isTerminatingState': False, 'B': 'S15'},\n",
              "  'S15': {'isTerminatingState': True}},\n",
              " {'startingState': 'S0',\n",
              "  'S0': {'isTerminatingState': False, 'A': 'S1'},\n",
              "  'S1': {'isTerminatingState': False, 'B': 'S2'},\n",
              "  'S2': {'isTerminatingState': False, 'A': 'S3', 'B': 'S4'},\n",
              "  'S3': {'isTerminatingState': False, 'A': 'S3', 'B': 'S5'},\n",
              "  'S4': {'isTerminatingState': False, 'A': 'S3', 'B': 'S4'},\n",
              "  'S5': {'isTerminatingState': True, 'A': 'S3', 'B': 'S4'}},\n",
              " {'startingState': 'S0',\n",
              "  'S0': {'isTerminatingState': False, 'A': 'S2'},\n",
              "  'S1': {'isTerminatingState': True, 'A': 'S4', 'B': 'S3'},\n",
              "  'S2': {'isTerminatingState': False, 'B': 'S3'},\n",
              "  'S3': {'isTerminatingState': False, 'A': 'S4', 'B': 'S3'},\n",
              "  'S4': {'isTerminatingState': False, 'A': 'S4', 'B': 'S1'}})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "regex = input(\"Please Enter a Regex: \")\n",
        "regextoMinimizedDFA(regex)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}